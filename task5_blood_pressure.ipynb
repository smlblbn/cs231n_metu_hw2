{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blood Pressure from PPG signal\n",
    "\n",
    "In this notebook, you should solve the problem in Task 4 (blood pressure estimation from PPG signal) in the first assignment (<a href=\"http://kovan.ceng.metu.edu.tr/~sinan/DL/HW1.html\">HW1</a>) using a CNN architecture that you should construct using the layers and the network you developed in this HW.\n",
    "\n",
    "The notebook is intentionally composed of only this cell. You can copy-paste any text, data, cell, or code that you developed in this HW or HW1. You can add as many cells as you want. You can create files on the disk as freely as you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from metu.data_utils import load_dataset\n",
    "from cs231n.classifiers.cnn import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in the training set:  8999\n",
      "Number of instances in the validation set:  100\n",
      "Number of instances in the testing set:  600\n"
     ]
    }
   ],
   "source": [
    "# Load the PPG dataset\n",
    "# If your memory turns out to be sufficient, try loading a subset\n",
    "def get_data(datafile, training_ratio=0.9, test_ratio=0.06, val_ratio=0.01):\n",
    "  # Load the PPG training data \n",
    "  X, y = load_dataset(datafile)\n",
    "    \n",
    "  # TODO: Split the data into training, validation and test sets\n",
    "  length=len(y)\n",
    "  num_training=int(length*training_ratio)\n",
    "  num_val = int(length*val_ratio)\n",
    "  num_test = min((length-num_training-num_val), int(length*test_ratio))\n",
    "  mask = range(num_training-1)\n",
    "  X_train = X[mask]\n",
    "  y_train = y[mask]\n",
    "  mask = range(num_training, num_training+num_test)\n",
    "  X_test = X[mask]\n",
    "  y_test = y[mask]\n",
    "  mask = range(num_training+num_test, num_training+num_test+num_val)\n",
    "  X_val = X[mask]\n",
    "  y_val = y[mask]\n",
    "  \n",
    "  return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "datafile = 'metu/dataset/Part_1.mat' #TODO: PATH to your data file\n",
    "input_size = 1000 #2 # TODO: Size of the input of the network\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_data(datafile)\n",
    "print \"Number of instances in the training set: \", len(X_train)\n",
    "print \"Number of instances in the validation set: \", len(X_val)\n",
    "print \"Number of instances in the testing set: \", len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(8999, 1, 10, 100)\n",
    "X_val = X_val.reshape(100, 1, 10, 100)\n",
    "X_test = X_test.reshape(600, 1, 10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter arrays\n",
    "best_net = None\n",
    "results = {}\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "epochs = 20\n",
    "optimizations = ['rmsprop']#, 'momentum', 'sgd']\n",
    "filter_size = [3]#, 7]\n",
    "filter_numbers = [500]#, 64, 32]\n",
    "batch_size = [32]#, 64, 32]\n",
    "learning_rate = [1e-2]#, 9e-5, 1e-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting iteration  0\n",
      "Finished epoch 0 / 20: train loss 321724.408694 validation loss 871240.822675\n",
      "starting iteration  10\n",
      "starting iteration  20\n",
      "starting iteration  30\n",
      "starting iteration  40\n",
      "starting iteration  50\n",
      "Finished epoch 0 / 20: train loss 21482.205601 validation loss 44103.782500\n",
      "starting iteration  60\n",
      "starting iteration  70\n",
      "starting iteration  80\n",
      "starting iteration  90\n",
      "starting iteration  100\n",
      "Finished epoch 0 / 20: train loss 10194.579374 validation loss 30393.629786\n",
      "starting iteration  110\n",
      "starting iteration  120\n",
      "starting iteration  130\n",
      "starting iteration  140\n",
      "starting iteration  150\n",
      "Finished epoch 0 / 20: train loss 7830.671990 validation loss 9071.771559\n",
      "starting iteration  160\n",
      "starting iteration  170\n",
      "starting iteration  180\n",
      "starting iteration  190\n",
      "starting iteration  200\n",
      "Finished epoch 0 / 20: train loss 7689.542611 validation loss 14242.349335\n",
      "starting iteration  210\n",
      "starting iteration  220\n",
      "starting iteration  230\n",
      "starting iteration  240\n",
      "starting iteration  250\n",
      "Finished epoch 0 / 20: train loss 9280.659388 validation loss 3557.153960\n",
      "starting iteration  260\n",
      "starting iteration  270\n",
      "starting iteration  280\n",
      "Finished epoch 1 / 20: train loss 6307.238739 validation loss 3656.129031\n",
      "starting iteration  290\n",
      "starting iteration  300\n",
      "Finished epoch 1 / 20: train loss 13523.492339 validation loss 5717.035151\n",
      "starting iteration  310\n",
      "starting iteration  320\n",
      "starting iteration  330\n",
      "starting iteration  340\n",
      "starting iteration  350\n",
      "Finished epoch 1 / 20: train loss 7565.794269 validation loss 9301.569990\n",
      "starting iteration  360\n",
      "starting iteration  370\n",
      "starting iteration  380\n",
      "starting iteration  390\n",
      "starting iteration  400\n",
      "Finished epoch 1 / 20: train loss 6317.979669 validation loss 6109.306962\n",
      "starting iteration  410\n",
      "starting iteration  420\n",
      "starting iteration  430\n",
      "starting iteration  440\n",
      "starting iteration  450\n",
      "Finished epoch 1 / 20: train loss 9761.954745 validation loss 7287.687258\n",
      "starting iteration  460\n",
      "starting iteration  470\n",
      "starting iteration  480\n",
      "starting iteration  490\n",
      "starting iteration  500\n",
      "Finished epoch 1 / 20: train loss 21857.687403 validation loss 12551.268082\n",
      "starting iteration  510\n",
      "starting iteration  520\n",
      "starting iteration  530\n",
      "starting iteration  540\n",
      "starting iteration  550\n",
      "Finished epoch 1 / 20: train loss 7276.496680 validation loss 4674.281331\n",
      "starting iteration  560\n",
      "Finished epoch 2 / 20: train loss 9680.672226 validation loss 2656.523821\n",
      "starting iteration  570\n",
      "starting iteration  580\n",
      "starting iteration  590\n",
      "starting iteration  600\n",
      "Finished epoch 2 / 20: train loss 10840.423789 validation loss 10070.225879\n",
      "starting iteration  610\n",
      "starting iteration  620\n",
      "starting iteration  630\n",
      "starting iteration  640\n",
      "starting iteration  650\n",
      "Finished epoch 2 / 20: train loss 4718.234711 validation loss 2299.044284\n",
      "starting iteration  660\n",
      "starting iteration  670\n",
      "starting iteration  680\n",
      "starting iteration  690\n",
      "starting iteration  700\n",
      "Finished epoch 2 / 20: train loss 10467.438049 validation loss 4535.850311\n",
      "starting iteration  710\n",
      "starting iteration  720\n",
      "starting iteration  730\n",
      "starting iteration  740\n",
      "starting iteration  750\n",
      "Finished epoch 2 / 20: train loss 12392.417151 validation loss 15474.248651\n",
      "starting iteration  760\n",
      "starting iteration  770\n",
      "starting iteration  780\n",
      "starting iteration  790\n",
      "starting iteration  800\n",
      "Finished epoch 2 / 20: train loss 5051.274913 validation loss 3810.117950\n",
      "starting iteration  810\n",
      "starting iteration  820\n",
      "starting iteration  830\n",
      "starting iteration  840\n",
      "Finished epoch 3 / 20: train loss 6709.312339 validation loss 5464.478637\n",
      "starting iteration  850\n",
      "Finished epoch 3 / 20: train loss 9972.317822 validation loss 5646.118124\n",
      "starting iteration  860\n",
      "starting iteration  870\n",
      "starting iteration  880\n",
      "starting iteration  890\n",
      "starting iteration  900\n",
      "Finished epoch 3 / 20: train loss 8607.626825 validation loss 1980.401150\n",
      "starting iteration  910\n",
      "starting iteration  920\n",
      "starting iteration  930\n",
      "starting iteration  940\n",
      "starting iteration  950\n",
      "Finished epoch 3 / 20: train loss 4317.963185 validation loss 3335.558691\n",
      "starting iteration  960\n",
      "starting iteration  970\n",
      "starting iteration  980\n",
      "starting iteration  990\n",
      "starting iteration  1000\n",
      "Finished epoch 3 / 20: train loss 6325.453021 validation loss 2491.587086\n",
      "starting iteration  1010\n",
      "starting iteration  1020\n",
      "starting iteration  1030\n",
      "starting iteration  1040\n",
      "starting iteration  1050\n",
      "Finished epoch 3 / 20: train loss 7137.379339 validation loss 2805.681713\n",
      "starting iteration  1060\n",
      "starting iteration  1070\n",
      "starting iteration  1080\n",
      "starting iteration  1090\n",
      "starting iteration  1100\n",
      "Finished epoch 3 / 20: train loss 7900.811852 validation loss 10442.466848\n",
      "starting iteration  1110\n",
      "starting iteration  1120\n",
      "Finished epoch 4 / 20: train loss 7555.791938 validation loss 9457.720339\n",
      "starting iteration  1130\n",
      "starting iteration  1140\n",
      "starting iteration  1150\n",
      "Finished epoch 4 / 20: train loss 4626.651540 validation loss 3962.551445\n",
      "starting iteration  1160\n",
      "starting iteration  1170\n",
      "starting iteration  1180\n",
      "starting iteration  1190\n",
      "starting iteration  1200\n",
      "Finished epoch 4 / 20: train loss 7198.154235 validation loss 3363.813090\n",
      "starting iteration  1210\n",
      "starting iteration  1220\n",
      "starting iteration  1230\n",
      "starting iteration  1240\n",
      "starting iteration  1250\n",
      "Finished epoch 4 / 20: train loss 8261.374278 validation loss 4131.231604\n",
      "starting iteration  1260\n",
      "starting iteration  1270\n",
      "starting iteration  1280\n",
      "starting iteration  1290\n",
      "starting iteration  1300\n",
      "Finished epoch 4 / 20: train loss 8824.930491 validation loss 6412.485698\n",
      "starting iteration  1310\n",
      "starting iteration  1320\n",
      "starting iteration  1330\n",
      "starting iteration  1340\n",
      "starting iteration  1350\n",
      "Finished epoch 4 / 20: train loss 11987.186630 validation loss 2442.840105\n",
      "starting iteration  1360\n",
      "starting iteration  1370\n",
      "starting iteration  1380\n",
      "starting iteration  1390\n",
      "starting iteration  1400\n",
      "Finished epoch 4 / 20: train loss 7337.831343 validation loss 5600.958980\n",
      "Finished epoch 5 / 20: train loss 11005.293775 validation loss 3732.229657\n",
      "starting iteration  1410\n",
      "starting iteration  1420\n",
      "starting iteration  1430\n",
      "starting iteration  1440\n",
      "starting iteration  1450\n",
      "Finished epoch 5 / 20: train loss 9285.316744 validation loss 5940.247925\n",
      "starting iteration  1460\n",
      "starting iteration  1470\n",
      "starting iteration  1480\n",
      "starting iteration  1490\n",
      "starting iteration  1500\n",
      "Finished epoch 5 / 20: train loss 5732.126765 validation loss 4593.901619\n",
      "starting iteration  1510\n",
      "starting iteration  1520\n",
      "starting iteration  1530\n",
      "starting iteration  1540\n",
      "starting iteration  1550\n",
      "Finished epoch 5 / 20: train loss 7666.769006 validation loss 3640.109918\n",
      "starting iteration  1560\n",
      "starting iteration  1570\n",
      "starting iteration  1580\n",
      "starting iteration  1590\n",
      "starting iteration  1600\n",
      "Finished epoch 5 / 20: train loss 7353.899172 validation loss 8478.116911\n",
      "starting iteration  1610\n",
      "starting iteration  1620\n",
      "starting iteration  1630\n",
      "starting iteration  1640\n",
      "starting iteration  1650\n",
      "Finished epoch 5 / 20: train loss 12602.632836 validation loss 39226.099221\n",
      "starting iteration  1660\n",
      "starting iteration  1670\n",
      "starting iteration  1680\n",
      "Finished epoch 6 / 20: train loss 5115.109881 validation loss 3417.256474\n",
      "starting iteration  1690\n",
      "starting iteration  1700\n",
      "Finished epoch 6 / 20: train loss 5174.258819 validation loss 5411.170661\n",
      "starting iteration  1710\n",
      "starting iteration  1720\n",
      "starting iteration  1730\n",
      "starting iteration  1740\n",
      "starting iteration  1750\n",
      "Finished epoch 6 / 20: train loss 6350.827288 validation loss 5836.333891\n",
      "starting iteration  1760\n",
      "starting iteration  1770\n",
      "starting iteration  1780\n",
      "starting iteration  1790\n",
      "starting iteration  1800\n",
      "Finished epoch 6 / 20: train loss 9138.906868 validation loss 10886.740248\n",
      "starting iteration  1810\n",
      "starting iteration  1820\n",
      "starting iteration  1830\n",
      "starting iteration  1840\n",
      "starting iteration  1850\n",
      "Finished epoch 6 / 20: train loss 16251.138680 validation loss 19570.052708\n",
      "starting iteration  1860\n",
      "starting iteration  1870\n",
      "starting iteration  1880\n",
      "starting iteration  1890\n",
      "starting iteration  1900\n",
      "Finished epoch 6 / 20: train loss 4829.984062 validation loss 3878.166989\n",
      "starting iteration  1910\n",
      "starting iteration  1920\n",
      "starting iteration  1930\n",
      "starting iteration  1940\n",
      "starting iteration  1950\n",
      "Finished epoch 6 / 20: train loss 9256.273331 validation loss 8516.283124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting iteration  1960\n",
      "Finished epoch 7 / 20: train loss 5884.135135 validation loss 2990.030663\n",
      "starting iteration  1970\n",
      "starting iteration  1980\n",
      "starting iteration  1990\n",
      "starting iteration  2000\n",
      "Finished epoch 7 / 20: train loss 6456.145477 validation loss 9769.256879\n",
      "starting iteration  2010\n",
      "starting iteration  2020\n",
      "starting iteration  2030\n",
      "starting iteration  2040\n",
      "starting iteration  2050\n",
      "Finished epoch 7 / 20: train loss 7375.590445 validation loss 7524.348080\n",
      "starting iteration  2060\n",
      "starting iteration  2070\n",
      "starting iteration  2080\n",
      "starting iteration  2090\n",
      "starting iteration  2100\n",
      "Finished epoch 7 / 20: train loss 7107.900022 validation loss 5135.852657\n",
      "starting iteration  2110\n",
      "starting iteration  2120\n",
      "starting iteration  2130\n",
      "starting iteration  2140\n",
      "starting iteration  2150\n",
      "Finished epoch 7 / 20: train loss 14263.662191 validation loss 7141.451781\n",
      "starting iteration  2160\n",
      "starting iteration  2170\n",
      "starting iteration  2180\n",
      "starting iteration  2190\n",
      "starting iteration  2200\n",
      "Finished epoch 7 / 20: train loss 6652.334024 validation loss 10472.833022\n",
      "starting iteration  2210\n",
      "starting iteration  2220\n",
      "starting iteration  2230\n",
      "starting iteration  2240\n",
      "Finished epoch 8 / 20: train loss 6005.981109 validation loss 3568.902200\n",
      "starting iteration  2250\n",
      "Finished epoch 8 / 20: train loss 7114.816478 validation loss 4491.313633\n",
      "starting iteration  2260\n",
      "starting iteration  2270\n",
      "starting iteration  2280\n",
      "starting iteration  2290\n",
      "starting iteration  2300\n",
      "Finished epoch 8 / 20: train loss 4352.317537 validation loss 3887.290572\n",
      "starting iteration  2310\n",
      "starting iteration  2320\n",
      "starting iteration  2330\n",
      "starting iteration  2340\n",
      "starting iteration  2350\n",
      "Finished epoch 8 / 20: train loss 5201.057795 validation loss 2846.589728\n",
      "starting iteration  2360\n",
      "starting iteration  2370\n",
      "starting iteration  2380\n",
      "starting iteration  2390\n",
      "starting iteration  2400\n",
      "Finished epoch 8 / 20: train loss 4945.115521 validation loss 8732.824169\n",
      "starting iteration  2410\n",
      "starting iteration  2420\n",
      "starting iteration  2430\n",
      "starting iteration  2440\n",
      "starting iteration  2450\n",
      "Finished epoch 8 / 20: train loss 4942.589070 validation loss 5237.451695\n",
      "starting iteration  2460\n",
      "starting iteration  2470\n",
      "starting iteration  2480\n",
      "starting iteration  2490\n",
      "starting iteration  2500\n",
      "Finished epoch 8 / 20: train loss 8631.401072 validation loss 22141.613147\n",
      "starting iteration  2510\n",
      "starting iteration  2520\n",
      "Finished epoch 9 / 20: train loss 7079.690801 validation loss 7272.166742\n",
      "starting iteration  2530\n",
      "starting iteration  2540\n",
      "starting iteration  2550\n",
      "Finished epoch 9 / 20: train loss 6667.233625 validation loss 3180.997257\n",
      "starting iteration  2560\n",
      "starting iteration  2570\n",
      "starting iteration  2580\n",
      "starting iteration  2590\n",
      "starting iteration  2600\n",
      "Finished epoch 9 / 20: train loss 7884.999483 validation loss 7631.693069\n",
      "starting iteration  2610\n",
      "starting iteration  2620\n",
      "starting iteration  2630\n",
      "starting iteration  2640\n",
      "starting iteration  2650\n",
      "Finished epoch 9 / 20: train loss 8817.135079 validation loss 13349.114477\n",
      "starting iteration  2660\n",
      "starting iteration  2670\n",
      "starting iteration  2680\n",
      "starting iteration  2690\n",
      "starting iteration  2700\n",
      "Finished epoch 9 / 20: train loss 5434.655359 validation loss 4903.962338\n",
      "starting iteration  2710\n",
      "starting iteration  2720\n",
      "starting iteration  2730\n",
      "starting iteration  2740\n",
      "starting iteration  2750\n",
      "Finished epoch 9 / 20: train loss 7038.762531 validation loss 3246.718411\n",
      "starting iteration  2760\n",
      "starting iteration  2770\n",
      "starting iteration  2780\n",
      "starting iteration  2790\n",
      "starting iteration  2800\n",
      "Finished epoch 9 / 20: train loss 5488.570497 validation loss 7458.092706\n",
      "Finished epoch 10 / 20: train loss 5329.600122 validation loss 3508.205624\n",
      "starting iteration  2810\n",
      "starting iteration  2820\n",
      "starting iteration  2830\n",
      "starting iteration  2840\n",
      "starting iteration  2850\n",
      "Finished epoch 10 / 20: train loss 6043.926959 validation loss 4000.384725\n",
      "starting iteration  2860\n",
      "starting iteration  2870\n",
      "starting iteration  2880\n",
      "starting iteration  2890\n",
      "starting iteration  2900\n",
      "Finished epoch 10 / 20: train loss 8590.365057 validation loss 16491.528550\n",
      "starting iteration  2910\n",
      "starting iteration  2920\n",
      "starting iteration  2930\n",
      "starting iteration  2940\n",
      "starting iteration  2950\n",
      "Finished epoch 10 / 20: train loss 5002.457900 validation loss 5264.821212\n",
      "starting iteration  2960\n",
      "starting iteration  2970\n",
      "starting iteration  2980\n",
      "starting iteration  2990\n",
      "starting iteration  3000\n",
      "Finished epoch 10 / 20: train loss 5790.459854 validation loss 12445.495151\n",
      "starting iteration  3010\n",
      "starting iteration  3020\n",
      "starting iteration  3030\n",
      "starting iteration  3040\n",
      "starting iteration  3050\n",
      "Finished epoch 10 / 20: train loss 5104.858317 validation loss 6306.845520\n",
      "starting iteration  3060\n",
      "starting iteration  3070\n",
      "starting iteration  3080\n",
      "starting iteration  3090\n",
      "Finished epoch 11 / 20: train loss 4051.078147 validation loss 5265.864200\n",
      "starting iteration  3100\n",
      "Finished epoch 11 / 20: train loss 6725.459301 validation loss 6269.248100\n",
      "starting iteration  3110\n",
      "starting iteration  3120\n",
      "starting iteration  3130\n",
      "starting iteration  3140\n",
      "starting iteration  3150\n",
      "Finished epoch 11 / 20: train loss 7197.669941 validation loss 29290.680905\n",
      "starting iteration  3160\n",
      "starting iteration  3170\n",
      "starting iteration  3180\n"
     ]
    }
   ],
   "source": [
    "# default architecture experiments\n",
    "for opt in optimizations:\n",
    "    for fs in filter_size:\n",
    "        for fn in filter_numbers:\n",
    "            for bs in batch_size:\n",
    "                for lr in learning_rate:\n",
    "                    model = init_cnn(weight_scale=1e-3, bias_scale=0, input_shape=(1, 1, 1000), \\\n",
    "                                         num_classes=2, num_filters=fn, filter_size=fs)\n",
    "                    best_model, train_loss_history, val_loss_history = train(X_train, y_train, X_val, y_val, \\\n",
    "                                                                             model, regresion_loss, update=opt, \\\n",
    "                                                                             reg=0.001, momentum=0.9, \\\n",
    "                                                                             learning_rate=lr, batch_size=bs, \\\n",
    "                                                                             num_epochs=epochs, acc_frequency=50, \\\n",
    "                                                                             verbose=True)\n",
    "                    results[(opt, fs, fn, bs, lr)] = train_loss_history, val_loss_history\n",
    "                    \n",
    "                    val_score = regresion_loss(X_val, best_model)\n",
    "                    val_loss = np.sum(np.square(val_score - y_val)) / 2\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        best_net = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimization: rmsprop filter_size: 3 filter_numbers: 96 batch_size: 32 learning_rate: 0.01\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for opt in optimizations:\n",
    "    for fs in filter_size:\n",
    "        for fn in filter_numbers:\n",
    "            for bs in batch_size:\n",
    "                for lr in learning_rate:\n",
    "                    loss_history = results[(opt, fs, fn, bs, lr)]\n",
    "                    print \"optimization: \" + opt + \" filter_size: \" + str(fs) + \" filter_numbers: \" + str(fn) \\\n",
    "                          + \" batch_size: \" + str(bs) + \" learning_rate: \" + str(lr)\n",
    "                    \n",
    "                    plt.subplot(2, 1, 2)\n",
    "                    plt.plot(results[opt, fs, fn, bs, lr][0], label='train')\n",
    "                    plt.plot(results[opt, fs, fn, bs, lr][1], label='val')\n",
    "                    plt.legend(loc='upper right', shadow=True)\n",
    "                    plt.title('Model Loss')\n",
    "                    plt.xlabel('Epoch')\n",
    "                    plt.ylabel('Loss')\n",
    "                    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error:  669.593425237616\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = regresion_loss(X_test, best_net)\n",
    "threshold = np.fabs(y_test_pred - y_test) - 0.1\n",
    "test_err = np.sum(np.square(np.maximum(0, threshold)), axis=1).mean()\n",
    "print 'Test error: ', test_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments About Experiment\n",
    "I created cnn.py file under clasifier directory. All function that are used in this notebook are in that file.\n",
    "I reimplemented init, train and loss funtion that are used in previous notebook. They adepted to implement regression model. Mean squared error used for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
